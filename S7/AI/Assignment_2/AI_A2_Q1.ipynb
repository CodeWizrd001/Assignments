{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_A2_Q1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx4_HifQhhSN"
      },
      "source": [
        "**Importing Required Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x49RBULhfaO"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn, optim\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTV-PlDVhnSW"
      },
      "source": [
        "**Configuring Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxg9vaZlhsO5"
      },
      "source": [
        "# Model Configs\n",
        "batch_size = 64\n",
        "learning_rate = 0.01\n",
        "cross_entropy = nn.CrossEntropyLoss()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlGmrn1jhv5V"
      },
      "source": [
        "**Load MNIST Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7HpOEHkhvDc"
      },
      "source": [
        "# Data Loader\n",
        "transform = torchvision.transforms.ToTensor()\n",
        "train_data = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST(\n",
        "    'mnist_data', train=True, download=True, transform=transform\n",
        "    ), batch_size=batch_size\n",
        ")\n",
        "val_data = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST(\n",
        "    'mnist_data', train=False, download=True, transform=transform\n",
        "    ), batch_size=batch_size\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk_pVsffh3tj"
      },
      "source": [
        "**Define Validation Function**\n",
        "\n",
        "Function to calculate accuracy of the given validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhQYvloyh2AU"
      },
      "source": [
        "# Validation function\n",
        "def validate(model, data):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(data):\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        y_pred = model(images)\n",
        "        value, pred = torch.max(y_pred, 1)\n",
        "        total += y_pred.size(0)\n",
        "        correct += torch.sum(pred == labels)\n",
        "    return correct * 100 / total"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BM5v-9wiDON"
      },
      "source": [
        "**Define Training Function**\n",
        "\n",
        "Function to train the model on the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b7lDn7FiA5J"
      },
      "source": [
        "# Training Function\n",
        "def train(model,epochs=5) :\n",
        "    optimizer = optim.Adam(model.parameters(),lr=learning_rate)    \n",
        "    for n in range(epochs)  :\n",
        "        for i , (images , labels) in enumerate(train_data) :\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            prediction = model(images)\n",
        "            loss = cross_entropy(prediction, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        accuracy = float(validate(model, val_data))\n",
        "        print(\"Epoch:\", n+1, \"Loss: \", float(loss.data), \"Accuracy:\", accuracy)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iToUF10uiO7G"
      },
      "source": [
        "**Define Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x6Pg10KiOUX"
      },
      "source": [
        "# Model\n",
        "class CNN(nn.Module) :\n",
        "    def __init__(self):\n",
        "        super(CNN,self).__init__()\n",
        "        self.conv_1 = nn.Conv2d(in_channels=1,out_channels=8,kernel_size=3)\n",
        "        self.conv_2 = nn.Conv2d(in_channels=8,out_channels=16,kernel_size=3)\n",
        "        self.dense_1 = nn.Linear(in_features=9216,out_features=2048)\n",
        "        self.dense_2 = nn.Linear(in_features=2048,out_features=10)\n",
        "\n",
        "        self.tanh = nn.Tanh()\n",
        "    def forward(self,x) :\n",
        "        x = self.tanh(self.conv_1(x))\n",
        "        x = self.tanh(self.conv_2(x))\n",
        "        x = x.view(x.shape[0],-1)\n",
        "        x = self.tanh(self.dense_1(x))\n",
        "        x = self.dense_2(x)\n",
        "        # output = self.tanh(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG2jvkZ4ikUo"
      },
      "source": [
        "**Create Model Instance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH9AmS8ihN86"
      },
      "source": [
        "# Model\n",
        "model = CNN().cuda()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhSlNb-4iSka"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJnEY50Lihv4",
        "outputId": "3c6bc9d5-5386-4ce0-ab58-eec3626bc879"
      },
      "source": [
        "# Summary\n",
        "summary(model, (1, 28, 28))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 26, 26]              80\n",
            "              Tanh-2            [-1, 8, 26, 26]               0\n",
            "            Conv2d-3           [-1, 16, 24, 24]           1,168\n",
            "              Tanh-4           [-1, 16, 24, 24]               0\n",
            "            Linear-5                 [-1, 2048]      18,876,416\n",
            "              Tanh-6                 [-1, 2048]               0\n",
            "            Linear-7                   [-1, 10]          20,490\n",
            "================================================================\n",
            "Total params: 18,898,154\n",
            "Trainable params: 18,898,154\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.25\n",
            "Params size (MB): 72.09\n",
            "Estimated Total Size (MB): 72.35\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_08r8Q2uipuV"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvh3pfe9iso3",
        "outputId": "181316dd-7104-49e6-c70e-65c16d6d55e5"
      },
      "source": [
        "# Train for 30 Epochs\n",
        "train(model,epochs=30)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Loss:  0.11636315286159515 Accuracy: 80.95999908447266\n",
            "Epoch: 2 Loss:  0.5661401152610779 Accuracy: 83.7699966430664\n",
            "Epoch: 3 Loss:  0.2669124901294708 Accuracy: 78.75999450683594\n",
            "Epoch: 4 Loss:  0.023944273591041565 Accuracy: 76.33999633789062\n",
            "Epoch: 5 Loss:  0.19102716445922852 Accuracy: 73.7699966430664\n",
            "Epoch: 6 Loss:  0.3458019196987152 Accuracy: 80.75\n",
            "Epoch: 7 Loss:  0.8541619181632996 Accuracy: 73.97999572753906\n",
            "Epoch: 8 Loss:  0.6575016975402832 Accuracy: 87.32999420166016\n",
            "Epoch: 9 Loss:  0.9873948097229004 Accuracy: 79.68999481201172\n",
            "Epoch: 10 Loss:  1.2695802450180054 Accuracy: 54.78999710083008\n",
            "Epoch: 11 Loss:  0.5420165657997131 Accuracy: 80.43999481201172\n",
            "Epoch: 12 Loss:  0.406747967004776 Accuracy: 75.54000091552734\n",
            "Epoch: 13 Loss:  0.20363746583461761 Accuracy: 77.48999786376953\n",
            "Epoch: 14 Loss:  0.1979249268770218 Accuracy: 90.23999786376953\n",
            "Epoch: 15 Loss:  0.1711551994085312 Accuracy: 83.43999481201172\n",
            "Epoch: 16 Loss:  0.367438942193985 Accuracy: 78.12999725341797\n",
            "Epoch: 17 Loss:  0.9625056385993958 Accuracy: 87.06999969482422\n",
            "Epoch: 18 Loss:  0.7076352834701538 Accuracy: 91.87999725341797\n",
            "Epoch: 19 Loss:  0.8148856163024902 Accuracy: 75.29999542236328\n",
            "Epoch: 20 Loss:  1.4365875720977783 Accuracy: 88.25\n",
            "Epoch: 21 Loss:  5.8842422731686383e-05 Accuracy: 85.57999420166016\n",
            "Epoch: 22 Loss:  0.34367749094963074 Accuracy: 86.15999603271484\n",
            "Epoch: 23 Loss:  0.6209620833396912 Accuracy: 84.5\n",
            "Epoch: 24 Loss:  0.24216501414775848 Accuracy: 84.43000030517578\n",
            "Epoch: 25 Loss:  0.5754142999649048 Accuracy: 89.02999877929688\n",
            "Epoch: 26 Loss:  8.868796430760995e-05 Accuracy: 91.39999389648438\n",
            "Epoch: 27 Loss:  0.18356508016586304 Accuracy: 89.44999694824219\n",
            "Epoch: 28 Loss:  0.00397390266880393 Accuracy: 89.22999572753906\n",
            "Epoch: 29 Loss:  0.016767730936408043 Accuracy: 90.11000061035156\n",
            "Epoch: 30 Loss:  0.0003581264754757285 Accuracy: 89.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2zBEfvKnI2d"
      },
      "source": [
        "We can see that the model is able to try and reduce the loss function with varying validation accuracies."
      ]
    }
  ]
}